{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3856c20a",
   "metadata": {},
   "source": [
    "# General approach\n",
    "1. **Define the business question clearly**\n",
    "   * “Do we want to predict churn (classification), forecast revenue (regression), segment customers (clustering), or optimize actions (RL)?”\n",
    "2.\t**Identify the type of problem**\n",
    "\t* Classification, regression, clustering, time series, anomaly detection, RL, etc.\n",
    "3.\t**Collect and prepare data**\n",
    "\t* Clean, preprocess, encode features, handle missing values.\n",
    "4.\t**Choose candidate algorithms**\n",
    "\t* Start simple (Logistic Regression, Decision Tree).\n",
    "\t* Scale up if needed (Random Forest, Gradient Boosting, Neural Networks).\n",
    "5.\t**Split data and evaluate**\n",
    "\t* Train/test (or cross-validation).\n",
    "\t* Use the right metrics (AUC, RMSE, log-loss, etc. depending on purpose).\n",
    "6.\t**Interpret results & refine**\n",
    "\t* Check for overfitting (train vs validation curves).\n",
    "\t* Use feature importance / SHAP for business insight.\n",
    "7.\t**Deploy & monitor**\n",
    "\t* Push to production, track drift, retrain when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c014994",
   "metadata": {},
   "source": [
    "## Modeling Techniques with Typical Questions\n",
    "\n",
    "| Category                         | Focus / Target                     | Typical Day-to-Day Questions                              | Typical Use Cases                            | Algorithms                                    |\n",
    "|----------------------------------|------------------------------------|-----------------------------------------------------------|----------------------------------------------|-----------------------------------------------|\n",
    "| **Discriminative Modeling**      | Learn boundaries that separate classes or predict outcomes | *“Will this customer churn or stay?”*<br>*“Is this transaction fraudulent?”* | Churn prediction, fraud detection, credit scoring | Logistic Regression, SVM, Decision Trees, Random Forests, Gradient Boosting |\n",
    "| **Generative Modeling**          | Model how data is generated (joint distribution P(X, Y)) → infer probabilities | *“Which class most likely generated this example?”*<br>*“If it’s spam, how do the words usually look?”* | Spam filtering, text classification, image generation | Naive Bayes, Gaussian Mixture Models (GMM), Hidden Markov Models (HMM), GANs, VAEs |\n",
    "| **Regression (Continuous Outcomes)** | Predict numeric values (continuous target variable) | *“What will our sales be next quarter?”*<br>*“How much revenue will this customer generate?”* | Revenue forecasting, demand prediction, customer lifetime value | Linear Regression, Polynomial Regression, Regression Trees, Gradient Boosting, Neural Nets |\n",
    "| **Unsupervised Structure Discovery** | No target → find hidden structure or reduce dimensionality | *“How many natural customer segments do we have?”*<br>*“Can we reduce features but keep most information?”* | Customer segmentation, anomaly detection, visualization | K-Means, DBSCAN, Hierarchical Clustering, PCA, t-SNE |\n",
    "| **Sequential Decision-Making (Reinforcement Learning)** | Learn policies that maximize cumulative reward over time | *“What’s the best pricing strategy over time?”*<br>*“Which product should we recommend next?”* | Dynamic pricing, recommender systems, robotics, supply chain optimization | Q-Learning, Deep Reinforcement Learning, Actor-Critic Methods |\n",
    "| **Time-to-Event / Risk Modeling (Survival Analysis)** | Predict time until an event occurs, handling censoring | *“When will this customer likely churn?”*<br>*“How long until a machine fails?”* | Churn timing, equipment failure, patient survival | Kaplan-Meier Estimator, Cox Proportional Hazards, Survival Forests |\n",
    "| **Time Series Forecasting**      | Predict future values along a timeline with temporal dependencies | *“What will our daily sales look like next month?”*<br>*“How much energy will be consumed tomorrow?”* | Sales prediction, financial forecasting, demand planning, energy usage | ARIMA, Exponential Smoothing (ETS), Prophet, LSTM, Transformers for sequences |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21768b6",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms — Comprehensive Overview\n",
    "\n",
    "| Algorithm / Family       | Type              | Typical Use Cases                           | Advantages                                                                 | Disadvantages                                                                 |\n",
    "|---------------------------|------------------|---------------------------------------------|----------------------------------------------------------------------------|-------------------------------------------------------------------------------|\n",
    "| **Linear Regression**     | Supervised (Regression) | Price prediction, sales forecasting         | Simple, interpretable                                                      | Assumes linearity, sensitive to outliers                                      |\n",
    "| **Polynomial Regression** | Supervised (Regression) | Modeling nonlinear trends                   | Captures curves with few features                                          | Overfitting risk at high degree                                               |\n",
    "| **Ridge / Lasso Regression** | Supervised (Regression) | Feature selection, collinearity handling    | Regularization prevents overfitting, handles multicollinearity             | Still assumes linearity                                                       |\n",
    "| **Logistic Regression**   | Supervised (Classification) | Churn prediction, credit scoring           | Probabilistic output, interpretable, fast                                  | Only linear decision boundaries                                               |\n",
    "| **Naive Bayes**           | Supervised (Classification) | Spam detection, text classification        | Very fast, works well with high-dimensional text                           | Strong independence assumption                                                |\n",
    "| **Support Vector Machine (SVM)** | Supervised (Classification/Regression) | Text/image classification                  | Works well in high dimensions, robust margin-based optimization            | Computationally heavy, hard to tune                                           |\n",
    "| **k-Nearest Neighbors (KNN)** | Supervised (Classification/Regression) | Recommendations, anomaly detection         | No training needed, simple, intuitive                                      | Slow predictions, sensitive to noise and scaling                              |\n",
    "| **Decision Tree**         | Supervised (Classification/Regression) | Segmentation, fraud detection              | Easy to interpret, handles non-linear relationships                        | Prone to overfitting                                                          |\n",
    "| **Random Forest**         | Supervised (Ensemble) | General-purpose classification/regression   | Robust, reduces overfitting, handles missing values                        | Slower prediction, less interpretable                                         |\n",
    "| **Gradient Boosting (XGBoost, LightGBM, CatBoost)** | Supervised (Ensemble) | Tabular data, ranking, Kaggle comps        | Very high accuracy, handles non-linearity, built-in regularization          | Needs tuning, longer training times                                           |\n",
    "| **Neural Networks (MLP, Deep Learning)** | Supervised | NLP, image/speech recognition, demand forecasting | Captures complex nonlinear patterns                                       | Requires lots of data, compute-heavy, black box                               |\n",
    "| **K-Means**               | Unsupervised (Clustering) | Customer segmentation, image compression    | Simple, scalable                                                           | Assumes spherical clusters, must choose k, sensitive to initialization        |\n",
    "| **Hierarchical Clustering** | Unsupervised (Clustering) | Taxonomy, document clustering              | Dendrograms interpretable                                                  | Poor scalability                                                              |\n",
    "| **DBSCAN**                | Unsupervised (Clustering) | Anomaly detection, spatial data             | Finds arbitrary cluster shapes, no need for k                              | Struggles with varying densities, high dimension data                         |\n",
    "| **Gaussian Mixture Models (GMM)** | Unsupervised (Clustering) | Soft clustering, anomaly detection         | Probabilistic cluster membership                                           | Assumes Gaussian-shaped clusters                                              |\n",
    "| **PCA (Principal Component Analysis)** | Unsupervised (Dim. Reduction) | Visualization, noise reduction             | Reduces dimensionality, speeds computation                                 | Components are hard to interpret                                              |\n",
    "| **t-SNE**                 | Unsupervised (Dim. Reduction) | Visualizing embeddings (2D/3D)             | Reveals local structure/clusters                                           | Computationally expensive, not predictive                                     |\n",
    "| **Apriori / FP-Growth**   | Unsupervised (Association Rule Mining) | Market basket analysis                     | Generates interpretable association rules                                  | Combinatorial explosion with many items                                       |\n",
    "| **ARIMA / ETS**           | Time Series      | Sales/finance forecasting                   | Interpretable, widely used                                                 | Requires stationarity, struggles with nonlinear data                          |\n",
    "| **Prophet (Facebook)**    | Time Series      | Business-friendly forecasting               | Handles trends, holidays automatically                                     | Less accurate on very noisy data                                              |\n",
    "| **LSTM / RNN**            | Time Series (Deep Learning) | Demand patterns, sequential data           | Captures long-term dependencies                                            | Data-hungry, hard to tune                                                     |\n",
    "| **Ensemble Methods (Bagging, Boosting, Stacking)** | Meta-approach | Fraud detection, competitions              | Improves accuracy and robustness                                           | Less interpretable, longer training                                           |\n",
    "| **Reinforcement Learning (Q-Learning, DQN, Actor-Critic)** | RL | Robotics, recommender systems, pricing     | Learns optimal policies by trial & error                                   | Data- and compute-intensive, slow convergence                                 |\n",
    "| **CNN (Convolutional Neural Network)** | Computer Vision | Image classification, object detection     | Great for spatial data, transfer learning possible                         | Requires large datasets, GPU resources                                        |\n",
    "| **Transformers (BERT, GPT)** | NLP (Deep Learning) | Text classification, translation, NER       | State-of-the-art performance, handles context well                         | Huge compute cost, less interpretable                                         |\n",
    "| **Isolation Forest**      | Anomaly Detection | Fraud, rare-event detection                 | Works well for high-dimensional data                                       | May miss subtle anomalies                                                     |\n",
    "| **One-Class SVM**         | Anomaly Detection | Intrusion detection                         | Effective for small datasets                                               | Scales poorly, kernel tuning required                                         |\n",
    "| **Autoencoders**          | Anomaly Detection (DL) | Outlier detection, dimensionality reduction| Learns compressed representation                                           | Needs tuning, less interpretable                                              |\n",
    "| **Collaborative Filtering** | Recommendation Systems | Product/movie recommendation               | Leverages user–item interactions                                          | Cold start problem, sparse data issues                                        |\n",
    "| **Content-Based Filtering** | Recommendation Systems | News, personalized feeds                   | Works with item metadata                                                   | Limited diversity, needs good features                                        |\n",
    "| **Hybrid Recommenders**   | Recommendation Systems | E-commerce, streaming services              | Combines collaborative + content-based                                     | More complex to implement                                                     |\n",
    "| **GANs (Generative Adversarial Networks)** | Generative Models | Image synthesis, data augmentation         | Generates realistic synthetic data                                         | Hard to train, instability issues                                             |\n",
    "| **Causal Inference (e.g., Uplift Modeling, Propensity Scoring)** | Specialized | Marketing experiments, healthcare          | Answers “what if” causal questions                                         | Strong assumptions, tricky validation                                         |\n",
    "| **Survival Analysis (CoxPH, Kaplan-Meier)** | Specialized | Customer churn, medical outcomes           | Handles time-to-event with censoring                                       | Needs careful interpretation                                                  |\n",
    "| **Explainable AI (XAI, SHAP, LIME)** | Meta-approach | Any ML application needing transparency    | Makes black-box models interpretable                                       | Adds complexity, approximation not always exact                               |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
