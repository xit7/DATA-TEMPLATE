{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6428df3",
   "metadata": {},
   "source": [
    "# Overview of Bayes’ Rule\n",
    "\n",
    "## Definition\n",
    "> Bayes’ Rule is a way to update probabilities when new evidence arrives.\n",
    "\n",
    "$$P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)}$$\n",
    "\n",
    "* $\\text{H}$ = Hypothesis (what you want to know, e.g., “I have a disease”)\n",
    "* $\\text{E}$ = Evidence (what you observe, e.g., “The test is positive”)\n",
    "* $\\text{P(H)}$ = Prior probability (belief before new evidence)\n",
    "* $\\text{P(E|H)}$ = Likelihood (chance of seeing evidence if hypothesis is true)\n",
    "* $\\text{P(H|E)}$ = Posterior probability (belief after seeing evidence)\n",
    "\n",
    "##  What is it Good For?\n",
    "* **Medical diagnosis**: Updating probability of a disease given test results.\n",
    "* **Spam filtering**: Classifying emails as spam/non-spam.\n",
    "* **Fraud detection**: Updating belief that a transaction is fraudulent given unusual activity.\n",
    "* **Machine learning**: Core of Naïve Bayes classifiers.\n",
    "\n",
    "\n",
    "## Example — Medical Testing\n",
    "**Suppose**:\n",
    "* 1% of people have a certain disease → P(H) = 0.01.\n",
    "* Test detects disease correctly 99% of the time (sensitivity) → P(E|H) = 0.99.\n",
    "* Test falsely says positive 5% of the time (false positive rate) → P(E|\\neg H) = 0.05.\n",
    "\n",
    "**Now, if you test positive, what’s the probability you actually have the disease?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccd9839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of having the disease given a positive test: 16.67%\n"
     ]
    }
   ],
   "source": [
    "# Bayes Rule Example: Disease Testing\n",
    "# Given a positive test, compute the probability of actually having the disease\n",
    "\n",
    "# Prior probability of disease\n",
    "P_H = 0.01  # 1%\n",
    "\n",
    "# Probability of positive test given disease (sensitivity)\n",
    "P_E_given_H = 0.99  \n",
    "\n",
    "# Probability of positive test given no disease (false positive rate)\n",
    "P_E_given_notH = 0.05  \n",
    "\n",
    "# Probability of NOT having the disease\n",
    "P_notH = 1 - P_H  \n",
    "\n",
    "# Total probability of testing positive\n",
    "P_E = P_E_given_H * P_H + P_E_given_notH * P_notH  \n",
    "\n",
    "# Apply Bayes' Rule\n",
    "P_H_given_E = (P_E_given_H * P_H) / P_E\n",
    "\n",
    "print(f\"Probability of having the disease given a positive test: {P_H_given_E:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0969521",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "* **Goal**: Classify data into categories using Bayes’s Rule.\n",
    "* **Naive assumption**: Features are independent given the class.\n",
    "* **Why \"naive**\": In reality features are often correlated, but the independence assumption works surprisingly well.\n",
    "* **Use cases**: Spam filtering, sentiment analysis, document classification, fraud detection.\n",
    "\n",
    "## Example: Spam Classifier\n",
    "We want to classify emails as Spam or Not Spam based on words.\n",
    "\n",
    "Suppose our training data is small:\n",
    "\n",
    "| Email   | Contains \"Buy\" | Contains \"Offer\" | Class    |\n",
    "| ------- | -------------- | ---------------- | -------- |\n",
    "| Email 1 | Yes            | Yes              | Spam     |\n",
    "| Email 2 | Yes            | No               | Spam     |\n",
    "| Email 3 | No             | Yes              | Not Spam |\n",
    "| Email 4 | No             | No               | Not Spam |\n",
    "\n",
    "## Manual Walkthrough\n",
    "Prior probabilities: P(\\text{Spam}) = 0.5, \\quad P(\\text{Not Spam}) = 0.5\n",
    "\n",
    "Likelihoods:\n",
    "\n",
    "* $P(\\text{Buy}|\\text{Spam}) = 1/2$\n",
    "* $P(\\text{Offer}|\\text{Spam}) = 1/2$\n",
    "* $P(\\text{Buy}|\\text{Not Spam}) = 0/2 = 0$\n",
    "* $P(\\text{Offer}|\\text{Not Spam}) = 1/2$\n",
    "To avoid zeros, we usually use Laplace smoothing.\n",
    "\n",
    "## Python Implementation (with Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f89425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('spam')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample dataset\n",
    "emails = [\n",
    "    \"Buy cheap offer now\",\n",
    "    \"Limited buy deal\",\n",
    "    \"Meeting schedule offer\",\n",
    "    \"Project discussion tomorrow\"\n",
    "]\n",
    "labels = [\"spam\", \"spam\", \"not spam\", \"not spam\"]\n",
    "\n",
    "# Convert text to feature counts (Bag-of-Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(emails)\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, labels)\n",
    "\n",
    "# Test new email\n",
    "test_email = [\"Cheap buy offer today\"]\n",
    "X_test = vectorizer.transform(test_email)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "prediction[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
